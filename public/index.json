[
{
	"uri": "//localhost:1313/4_modulefour_backend/01_dropdownapis.html",
	"title": "Build Dropdown APIs",
	"tags": [],
	"description": "",
	"content": "Build Dropdown APIs Let\u0026rsquo;s create two APIs to populate your filter dropdowns with paper categories and locations.\nStep 1: Create the Categories API Open API Builder: Press CMD/CTRL + U Create the API: Click \u0026ldquo;Add new API\u0026rdquo; Select your database integration Add the query: SELECT DISTINCT category_name FROM dm_operations.inventory; Test and save: Click \u0026ldquo;Run API\u0026rdquo; Click the pencil icon next to \u0026lsquo;API1\u0026rsquo; and rename it to \u0026ldquo;get_papercategories\u0026rdquo; Step 2: Create the Locations API Create the API: Click \u0026ldquo;Add new API\u0026rdquo; Select the same database integration Add the query: SELECT DISTINCT location_name FROM dm_operations.inventory; Test and save: Click \u0026ldquo;Run API\u0026rdquo; Click the pencil icon next to \u0026lsquo;API1\u0026rsquo; and rename it to \u0026ldquo;get_locations\u0026rdquo; Step 3: Connect Your Dropdowns Close API Builder (CMD/CTRL + U) Configure Categories dropdown: Select the Paper Categories dropdown In Properties panel: Find \u0026ldquo;Options\u0026rdquo; Clear placeholder data Add: {{get_papercategories.response}} Configure Locations dropdown: Select the Location dropdown In Properties panel: Find \u0026ldquo;Options\u0026rdquo; Clear placeholder data Add: {{get_locations.response}} Test both dropdowns after connecting the APIs. They should show real categories and locations. If no data appears, try clicking \u0026ldquo;Run API\u0026rdquo; again and verify your SQL queries.\nExample Here\u0026rsquo;s how you connect your dropdown components to the APIs: Next Steps Now that your dropdowns are working, let\u0026rsquo;s create the dynamic inventory data API.\n"
},
{
	"uri": "//localhost:1313/",
	"title": "Building a Full-Stack AI Application with AWS and Superblocks",
	"tags": [],
	"description": "",
	"content": "Building a Full-Stack AI Application with AWS and Superblocks [PLACEHOLDER - SUPERBLOCKS_LOGO] Welcome In this hands-on workshop, you\u0026rsquo;ll build a complete inventory and sales management dashboard using AWS services and Superblocks\u0026rsquo; application development platform. This enterprise-grade application will showcase how to combine modern UI components, secure APIs, and AI capabilities to deliver business value quickly.\nKey Benefits of Superblocks 10x Faster Development ‚ö°: Build in days what would normally take months Simplified AI Integration ü§ñ: Easily incorporate AWS Bedrock\u0026rsquo;s generative AI capabilities Enterprise-Ready üîí: Implement proper governance and security from day one Full-Stack Solution üèóÔ∏è: Create complete applications with frontend, backend, and AI components No ML Expertise Required üß†: Leverage advanced AI capabilities without specialized knowledge This workshop is ideal for developers, technical leaders, and solution architects looking to accelerate application development while incorporating powerful AI capabilities.\nWhat You\u0026rsquo;ll Build Your dashboard application will feature:\nInteractive inventory and sales visualizations AI-powered analysis and forecasting using AWS Bedrock Secure backend APIs and role-based access controls Production-ready deployment pipeline ::alert[The examples and sample code provided in this workshop are intended for learning purposes and demonstrate AWS and Superblocks best practices. They are not intended for production use.]{header=\u0026ldquo;Warning\u0026rdquo; type=\u0026ldquo;warning\u0026rdquo;}\nWorkshop Details Duration: 2-3 hours across multiple sections Cost: AWS Bedrock and RDS usage will incur charges. Superblocks offers a free 14-day trial. Clean-up: Follow the clean-up instructions after completion to avoid additional costs. [REMINDER TO ADD CLEAN-UP SECTION] "
},
{
	"uri": "//localhost:1313/3_modulethree_frontend/01_headernavigation.html",
	"title": "Building the Header Navigation",
	"tags": [],
	"description": "",
	"content": "Building the Header Navigation Let\u0026rsquo;s create a navigation header for your dashboard.\nStep 1: Add the Navigation Bar Click \u0026ldquo;Browse templates\u0026rdquo; in the top section Search for \u0026ldquo;Navigation bar with left aligned nav items\u0026rdquo; Click \u0026ldquo;Insert\u0026rdquo; Step 2: Add Your Logo (Optional) Remove the default logo: Click the \u0026ldquo;Acme inc.\u0026rdquo; icon Click delete Add your logo: Click \u0026ldquo;Add Component\u0026rdquo; Search for \u0026ldquo;Image\u0026rdquo; Select the image component Configure the image: Set the image URL Adjust the size as needed Example Here\u0026rsquo;s how your header should look after completion: Next Steps Now that your header is ready, let\u0026rsquo;s create the filter section.\n"
},
{
	"uri": "//localhost:1313/7_moduleseven_deployment/01_deployingapp.html",
	"title": "Deploying Your Application",
	"tags": [],
	"description": "",
	"content": "Deploying Your Application Let\u0026rsquo;s deploy your dashboard to production using Superblocks\u0026rsquo; simple deployment process.\nUnderstanding Deployment When you deploy with Superblocks:\nYour code runs on our Global Edge Network Changes apply instantly worldwide Users get fast access from anywhere When using Source Control, only commits on the default branch can be deployed. Make sure to merge your changes to make them deployable.\nDeploying Your Dashboard Open Version Control:\nClick Version Control icon in the sidebar Find your latest commit in the list Deploy your changes:\nClick the commit\u0026rsquo;s menu (‚ãÆ) Choose \u0026ldquo;Deploy\u0026rdquo; Review the changes Click \u0026ldquo;Confirm Deploy\u0026rdquo; Verify deployment:\nWait for deployment to complete Open your dashboard URL Test the new features Additional Deployment Options While UI deployment is recommended for this workshop, Superblocks also supports automated deployment through CI/CD:\nGitHub Actions Integration For production environments, you can automate deployment using this workflow:\nname: Deploy on: workflow_run: workflows: [\u0026#34;Sync changes to Superblocks\u0026#34;] types: - completed jobs: deploy: if: ${{ github.event.workflow_run.head_branch == \u0026#39;main\u0026#39; \u0026amp;\u0026amp; github.event.workflow_run.conclusion == \u0026#39;success\u0026#39; }} runs-on: ubuntu-latest name: Deploy steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Deploy uses: superblocksteam/deploy-action@v1 id: deploy with: token: ${{ secrets.SUPERBLOCKS_TOKEN }} Command Line Deployment For advanced users, Superblocks provides a CLI:\n# Install the CLI npm i -g @superblocksteam/cli # Log in and deploy superblocks login superblocks deploy Best Practices Before deploying:\nReview your changes Test in preview mode Check all features After deploying:\nVerify the deployment Test critical features Monitor for errors Use preview mode to test your changes before deploying to production.\nNext Steps Congratulations! Your Acme Incorporated dashboard is now live in production. Let\u0026rsquo;s look at what to do next.\n"
},
{
	"uri": "//localhost:1313/1_moduleone_overview.html",
	"title": "Overview",
	"tags": [],
	"description": "",
	"content": "Prerequisites and Setup What You\u0026rsquo;ll Learn In this first module, you\u0026rsquo;ll learn about:\nSuperblocks\u0026rsquo; Mission\nUnderstanding Superblock\u0026rsquo;s mission How Superblocks empowers developers The DIY Development Trap\nHow custom tooling leads to technical debt Why internal platforms create endless maintenance Solution Overview\nHow Superblocks addresses these development challenges Key platform features and capabilities This module provides the foundation for understanding why Superblocks is essential for modern enterprise application development. The concepts covered here will be applied throughout the workshop.\nThe examples and sample code provided in this workshop are intended for learning purposes. While they demonstrate best practices, you should adapt them to meet your specific production requirements.\nNext Steps Let\u0026rsquo;s begin by exploring Superblocks\u0026rsquo; mission and how it\u0026rsquo;s transforming enterprise application development.\n"
},
{
	"uri": "//localhost:1313/5_modulefive_bedrock/01_setupbedrock.html",
	"title": "Setting up AWS Bedrock",
	"tags": [],
	"description": "",
	"content": "Configuring AWS Bedrock in Superblocks üîå Superblocks makes it remarkably simple to integrate with AWS Bedrock. In this section, we\u0026rsquo;ll configure the connection between your Superblocks application and AWS Bedrock.\nStep 1: Configure AWS "
},
{
	"uri": "//localhost:1313/1_moduleone_overview/01_superblocksmission.html",
	"title": "Superblocks&#39; Mission",
	"tags": [],
	"description": "",
	"content": "Superblocks\u0026rsquo; Mission Empowering the next billion developers! Enterprises today face mounting challenges with DIY software development approaches. Building and maintaining custom internal tools creates technical debt, while fragmented development processes and governance challenges slow innovation. Teams get caught in endless cycles of maintenance, struggling to keep up with security requirements and feature requests. Traditional approaches not only create barriers between technical and business teams but also drain resources that could be spent on core business innovation.\nSuperblocks changes this equation entirely. We\u0026rsquo;ve created a platform where developers can build production-ready applications without getting bogged down in infrastructure setup, security configurations, or deployment pipelines. What used to take weeks of setup and maintenance now happens automatically, letting your team deliver value while meeting enterprise standards from day one.\nBy combining AI-powered development with enterprise-grade security, Superblocks transforms how organizations approach software development. We\u0026rsquo;re enabling teams to focus on innovation instead of infrastructure management, empowering the next billion developers to create extraordinary solutions that drive their businesses forward.\nPlatform Overview Next Steps In the next section, you will learn more about the challenges that Superblocks addresses and gain an understanding of the key technical concepts that are important for successfully leveraging the platform.\n"
},
{
	"uri": "//localhost:1313/6_modulesix_governance/01_useridentification.html",
	"title": "User Identification",
	"tags": [],
	"description": "",
	"content": "User Identification Let\u0026rsquo;s display user information in your dashboard to help users identify who\u0026rsquo;s logged in.\nStep 1: Set Up User Display Find the user icon:\nLook in the top-right corner Click to select the icon component Add the user\u0026rsquo;s name:\nOpen the Properties panel Find the \u0026ldquo;Label\u0026rdquo; field Add this JavaScript: {{Global.user.name}} Working with User Context The Global.user object gives you access to:\nname: Full name email: Email address groups: Access groups metadata: Additional info Example uses:\n// Display name {{Global.user.name}} // Show email {{Global.user.email}} // Check admin access {{Global.user.groups.includes(\u0026#39;admin\u0026#39;)}} The Global.user object is always available and automatically stays in sync with the current user\u0026rsquo;s session.\nNext Steps Now that users can identify themselves, let\u0026rsquo;s set up access controls.\n"
},
{
	"uri": "//localhost:1313/2_moduletwo_preqandsetup/01_workshopoverview.html",
	"title": "Workshop Overview",
	"tags": [],
	"description": "",
	"content": "Workshop Overview Welcome to the Superblocks workshop! Together, we\u0026rsquo;ll build a full-stack AI application for Acme Incorporated. You\u0026rsquo;ll create a modern, interactive dashboard featuring:\nDynamic data filtering Real-time statistics and insights Interactive data visualization Role-based access control Technical Requirements To get started, you\u0026rsquo;ll need:\n1. Web Browser\nChrome (recommended) Firefox Safari 2. Superblocks Account\nPermission to create apps (role can be owner, admin, or developer) 3. Database with proper credentials\nPermissions to write data (needed to initially set up mock data) Permissions to read data 4. Programming Knowledge\nBasic SQL and Python skills No JavaScript/TypeScript experience needed Time Requirements The workshop is divided into six modules:\nPrerequisites and Setup (30 minutes) Building the Frontend (30 minutes) Building the Backend (30 minutes) Integrating with AWS Bedrock (20 minutes) Governance \u0026amp; Access Controls (30 minutes) Deploying the Application (10 minutes) Total estimated time is 2 to 3 hours\nNext Steps In the next section, we\u0026rsquo;ll set up your Superblocks account and database resources, then generate the mock data needed for the workshop.\n"
},
{
	"uri": "//localhost:1313/3_modulethree_frontend/02_filtersection.html",
	"title": "Creating the Filter Section",
	"tags": [],
	"description": "",
	"content": "Creating the Filter Section Let\u0026rsquo;s add filters to help users interact with the dashboard data.\nStep 1: Create the Filter Container Add a new section: Click \u0026lsquo;+ Add Section\u0026rsquo; below the navigation bar A new section with a column component will appear Configure the layout: Set layout to \u0026ldquo;Horizontal\u0026rdquo; Set \u0026ldquo;Vertical align\u0026rdquo; to \u0026ldquo;Bottom\u0026rdquo; Step 2: Add Filter Components Add dropdowns: Click \u0026ldquo;Add Component\u0026rdquo; in the column Add two dropdown components: First dropdown: Label = \u0026ldquo;Paper Categories\u0026rdquo; Second dropdown: Label = \u0026ldquo;Location\u0026rdquo; Set both widths to \u0026ldquo;Fill Parent\u0026rdquo; Add buttons: Add two button components: First button: Label = \u0026ldquo;Submit\u0026rdquo; Second button: Label = \u0026ldquo;Reset Filters\u0026rdquo; The horizontal layout ensures all filter components are aligned properly in a single row and removes the need to use CSS or Flexbox to align components.\nExample Here\u0026rsquo;s how you create your filter section: Next Steps Next, we\u0026rsquo;ll create the hero stats section to display your key metrics.\n"
},
{
	"uri": "//localhost:1313/4_modulefour_backend/02_inventoryapi.html",
	"title": "Creating the Inventory Data API",
	"tags": [],
	"description": "",
	"content": "Creating the Inventory Data API Let\u0026rsquo;s create a dynamic API that filters inventory data based on your dropdown selections.\nStep 1: Create the Inventory API Open API Builder: Press CMD/CTRL + U Create the API: Click \u0026ldquo;Add new API\u0026rdquo; Select your database integration Add the query: SELECT * FROM dm_operations.inventory WHERE ({{Dropdown1?.selectedOptionValue || \u0026#39;\u0026#39;}} = \u0026#39;\u0026#39; OR category_name = {{Dropdown1?.selectedOptionValue || \u0026#39;\u0026#39;}}) AND ({{Dropdown2?.selectedOptionValue || \u0026#39;\u0026#39;}} = \u0026#39;\u0026#39; OR location_name = {{Dropdown2?.selectedOptionValue || \u0026#39;\u0026#39;}}); Test and save: Click \u0026ldquo;Run API\u0026rdquo; Click the pencil icon next to \u0026ldquo;API1\u0026rdquo; and rename it to \u0026ldquo;get_inventory_data\u0026rdquo; Make sure your dropdown component names match Dropdown1 and Dropdown2. If you used different names, update them in the SQL query.\nStep 2: Connect Your Table Configure the table: Select the Table component In Properties panel: Clear the \u0026ldquo;Data\u0026rdquo; field Add: {{get_inventory_data.response}} Step 3: Set Up Actions Configure Submit button:\nSelect the \u0026ldquo;Submit\u0026rdquo; button Add onClick handler: Click + next to \u0026ldquo;Event handlers\u0026rdquo; Choose \u0026ldquo;Run APIs\u0026rdquo; Select \u0026ldquo;get_inventory_data\u0026rdquo; Configure Reset button:\nSelect the \u0026ldquo;Reset Filters\u0026rdquo; button Add first reset action: Click + next to \u0026ldquo;Event handlers\u0026rdquo; Choose \u0026ldquo;Reset component to default\u0026rdquo; Select \u0026ldquo;Dropdown1\u0026rdquo; (keep \u0026ldquo;Selected Option\u0026rdquo;) Add second reset action: Click + again Choose \u0026ldquo;Reset component to default\u0026rdquo; Select \u0026ldquo;Dropdown2\u0026rdquo; (keep \u0026ldquo;Selected Option\u0026rdquo;) Add refresh action: Click + again Choose \u0026ldquo;Run APIs\u0026rdquo; Select \u0026ldquo;get_inventory_data\u0026rdquo; Your table will now update dynamically based on the selected filters.\nTesting Test filtering: Try different filter combinations Click Submit to apply filters Verify data updates correctly Test reset: Click Reset Filters Verify dropdowns clear Check if table refreshes If the table is empty, try clicking \u0026ldquo;Run API\u0026rdquo; in the API Builder Tool.\nNext Steps Now that your inventory API is working, let\u0026rsquo;s create the hero stats APIs.\n"
},
{
	"uri": "//localhost:1313/getting-started.html",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Workshop architecture The following architecture diagram illustrates the various components of the workshop.\nPreparing for the workshop Follow the installation instructions in this section to prepare your environment for the workshop.\nIf you are attending an AWS guided event, setup your environment here. If you are not participating in an AWS guided event, setup your environment here. ::alert[If you are running this workshop on your own AWS account, remember to delete all resources by following the Clean Up Resources section to avoid unnecessary charges.]{header=Note}\n"
},
{
	"uri": "//localhost:1313/6_modulesix_governance/02_accesscontrol.html",
	"title": "Implementing Access Control",
	"tags": [],
	"description": "",
	"content": "Implementing Access Control Let\u0026rsquo;s secure your dashboard by controlling who can access sensitive features.\nStep 1: Add Access Rules Find the Invoices tab:\nLocate \u0026ldquo;Invoices\u0026rdquo; in the navigation Select to view its properties Create visibility rule:\nFind \u0026ldquo;Visibility\u0026rdquo; under Layout Add this access check: {{[\u0026#39;John Smith\u0026#39;, \u0026#39;Sarah Johnson\u0026#39;, \u0026#39;Michael Lee\u0026#39;].includes(Global.user.name)}} How Access Control Works This rule:\nOnly shows Invoices to listed users Hides it from everyone else Keeps the UI clean and secure More Access Examples Control access by group membership:\n// Manager-only features {{Global.user.groups.includes(\u0026#39;manager\u0026#39;)}} // Admin dashboard access {{Global.user.groups.includes(\u0026#39;admin\u0026#39;)}} Security Best Practices Secure both UI and APIs Use consistent rules Keep rules simple Document permissions UI controls are not enough! It is always recommended to secure your APIs too.\nNext Steps Let\u0026rsquo;s test your access controls to make sure they work.\n"
},
{
	"uri": "//localhost:1313/5_modulefive_bedrock/02_inventoryanalysis.html",
	"title": "Inventory Analysis with Bedrock",
	"tags": [],
	"description": "",
	"content": "Building an Inventory Analysis Feature üì¶ Now that we have our Bedrock connection set up, let\u0026rsquo;s create a powerful inventory analysis feature that can provide insights about current inventory levels, identify potential stockouts, and recommend transfering strategies.\nStep 1: Create the Inventory Analysis API Navigate to API Builder in the left sidebar Open the API Builder Tool (CMD/CTRL + U) Search for the integration to your database (AWS RDS if applicable) Name your API \u0026ldquo;generate_insights\u0026rdquo; Add the below SQL and rename the step to \u0026ldquo;get_input_data\u0026rdquo; SELECT ils.inventory_id, ils.sku, ils.product_name, ils.category_name, ils.location_name, ils.current_stock, ils.reorder_point, ils.stock_margin, ils.stock_status, sv.daily_velocity, po.total_quantity_ordered FROM dm_operations.inventory_location_status ils LEFT JOIN dm_operations.sales_velocity sv ON ils.inventory_id = sv.inventory_id AND ils.location_name = sv.location_name LEFT JOIN dm_operations.pending_orders po ON ils.inventory_id = po.inventory_id AND ils.location_name = po.location_name; Underneath the first step, add a new Python step Add the below Python code to limit the input data size and rename the step to \u0026ldquo;simplify_input_data\u0026rdquo; def prepare_data_for_llm(input_data): import json # Convert JSON object to a formatted string representation if isinstance(input_data, (dict, list)): # Convert to a nicely formatted string with indentation formatted_string = json.dumps(input_data, indent=2) # Truncate if too large max_chars = 8000 if len(formatted_string) \u0026gt; max_chars: formatted_string = formatted_string[:max_chars] + \u0026#34;\\n...(truncated)\u0026#34; return formatted_string # Call the function return prepare_data_for_llm(get_input_data.output) Add an additional Python step and the below code to call AWS Bedrock Rename the step to \u0026ldquo;send_to_bedrock\u0026rdquo; import boto3 import json def send_to_bedrock(text_data): # Truncate data text_data = text_data[:5000] # Create client client = boto3.client( service_name=\u0026#34;bedrock-runtime\u0026#34;, region_name=aws_region, aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key, ) # Create prompt as a message prompt = f\u0026#34;\u0026#34;\u0026#34;Analyze this inventory data: {text_data} Give me 3 inventory transfer recommendations across 3 different locations with: - Product name - From location - To location - Quantity - Priority score (0-100) - Cost savings - Reasoning - Analysis points (demand, cost, impact) Make sure to the reasoning is informative and not a generic statement. The reasoning should be different for each recommendation. Do not restate the analysis points in the response and can include information on forecased demand in rationale. Return as a JSON array.\u0026#34;\u0026#34;\u0026#34; # Make request with content as an array response = client.invoke_model( modelId=\u0026#34;amazon.nova-lite-v1:0\u0026#34;, body=json.dumps( {\u0026#34;messages\u0026#34;: [{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [{\u0026#34;text\u0026#34;: prompt}]}]} ), contentType=\u0026#34;application/json\u0026#34;, accept=\u0026#34;application/json\u0026#34;, ) # Parse the response response_body = json.loads(response[\u0026#34;body\u0026#34;].read()) # Check response structure and extract accordingly if \u0026#34;content\u0026#34; in response_body and isinstance(response_body[\u0026#34;content\u0026#34;], list): output = response_body[\u0026#34;content\u0026#34;][0][\u0026#34;text\u0026#34;] else: # Fallback if response format is different output = str(response_body) return {\u0026#34;raw_output\u0026#34;: output} # Call the function return send_to_bedrock(simplify_input_data.output) Add a 4th and final Python step with the below code, and rename it to \u0026ldquo;format_output\u0026rdquo; import json import re def parse_text_recommendations(raw_output): try: # Get the raw output string if isinstance(raw_output, dict) and \u0026#34;raw_output\u0026#34; in raw_output: text = raw_output[\u0026#34;raw_output\u0026#34;] else: text = str(raw_output) # Extract the JSON array from the code block using regex json_match = re.search(r\u0026#34;```json\\s*\\n(.*?)\\n\\s*```\u0026#34;, text, re.DOTALL) if json_match: json_text = json_match.group(1) # Parse the extracted JSON directly recommendations = json.loads(json_text) return recommendations # If we can\u0026#39;t find a code block, try to parse the nested structure # First convert single quotes to double quotes for proper JSON parsing # But be careful with nested quotes in the JSON content if text.startswith(\u0026#34;{\u0026#39;\u0026#34;): # This is a Python dict representation, not valid JSON # Use ast.literal_eval which is safer than eval import ast data = ast.literal_eval(text) # Navigate through the nested structure if \u0026#34;output\u0026#34; in data and \u0026#34;message\u0026#34; in data[\u0026#34;output\u0026#34;]: message = data[\u0026#34;output\u0026#34;][\u0026#34;message\u0026#34;] if \u0026#34;content\u0026#34; in message and isinstance(message[\u0026#34;content\u0026#34;], list): content_text = message[\u0026#34;content\u0026#34;][0][\u0026#34;text\u0026#34;] # Extract JSON from code block json_match = re.search( r\u0026#34;```json\\s*\\n(.*?)\\n\\s*```\u0026#34;, content_text, re.DOTALL ) if json_match: json_text = json_match.group(1) recommendations = json.loads(json_text) return recommendations # If all else fails, run the original regex pattern pattern = r\u0026#34;(\\d+)\\.\\s+Product name:\\s+(.*?)\\nFrom location:\\s+(.*?)\\nTo location:\\s+(.*?)\\nQuantity:\\s+(.*?)\\nPriority score.*?:\\s+(.*?)\\nCost savings:\\s+(.*?)\\nReasoning:\\s+(.*?)(?=\\n\\n\\d+\\.|\\n\\nPlease|\\Z)\u0026#34; matches = re.findall(pattern, text, re.DOTALL) if matches: recommendations = [] for match in matches: recommendation = { \u0026#34;product_name\u0026#34;: match[1].strip(), \u0026#34;from_location\u0026#34;: match[2].strip(), \u0026#34;to_location\u0026#34;: match[3].strip(), \u0026#34;quantity\u0026#34;: match[4].strip(), \u0026#34;priority_score\u0026#34;: match[5].strip(), \u0026#34;cost_savings\u0026#34;: match[6].strip(), \u0026#34;reasoning\u0026#34;: match[7].strip(), } # Try to convert numeric fields try: recommendation[\u0026#34;quantity\u0026#34;] = int(recommendation[\u0026#34;quantity\u0026#34;]) except: pass try: recommendation[\u0026#34;priority_score\u0026#34;] = int( recommendation[\u0026#34;priority_score\u0026#34;] ) except: pass recommendations.append(recommendation) return recommendations return { \u0026#34;error\u0026#34;: \u0026#34;Could not parse recommendations from output\u0026#34;, \u0026#34;original_output\u0026#34;: text, } except Exception as e: # Custom extraction as a last resort try: # Direct extraction of the JSON array from the text start_idx = text.find(\u0026#34;[\\\\n {\u0026#34;) end_idx = text.find(\u0026#34;]\\\\n```\u0026#34;) if start_idx != -1 and end_idx != -1: json_text = text[start_idx : end_idx + 1] # Replace escaped characters json_text = ( json_text.replace(\u0026#34;\\\\n\u0026#34;, \u0026#34;\\n\u0026#34;) .replace(\u0026#39;\\\\\u0026#34;\u0026#39;, \u0026#39;\u0026#34;\u0026#39;) .replace(\u0026#34;\\\\\u0026#39;\u0026#34;, \u0026#34;\u0026#39;\u0026#34;) ) recommendations = json.loads(json_text) return recommendations except: pass return {\u0026#34;error\u0026#34;: str(e), \u0026#34;original_output\u0026#34;: raw_output} # Call the function with the Bedrock output raw_output = send_to_bedrock.output return parse_text_recommendations(raw_output) Click Run API to test your API When crafting prompts for foundation models, be specific about the format and type of analysis you want. This helps ensure consistent, useful responses.\nYou\u0026rsquo;ve now created a powerful inventory analysis feature that leverages AWS Bedrock to provide actionable insights. This feature demonstrates how Superblocks and AWS Bedrock can work together to transform raw data into valuable business intelligence.\nNext Steps "
},
{
	"uri": "//localhost:1313/2_moduletwo_preqandsetup.html",
	"title": "Prerequisites and Setup",
	"tags": [],
	"description": "",
	"content": "Module 2: Prerequisites and Setup What You\u0026rsquo;ll Learn In this module, you\u0026rsquo;ll:\nGet an overview of the application we\u0026rsquo;ll build Set up your Superblocks account and database access Generate and verify sample data for the workshop Learn about the technical architecture Time to Complete This module should take approximately 30 minutes to complete.\nNext Steps Let\u0026rsquo;s start with an overview of the application we\u0026rsquo;ll build together.\n"
},
{
	"uri": "//localhost:1313/2_moduletwo_preqandsetup/02_setup.html",
	"title": "Resource Setup",
	"tags": [],
	"description": "",
	"content": "Resource Setup Prerequisites To complete this workshop, you\u0026rsquo;ll need:\nA Superblocks Account Database Access A Modern Web Browser (Chrome recommended) Step 1: Superblocks Account Setup Create a Superblocks Account\nGo to superblocks.com Click \u0026ldquo;Login\u0026rdquo; then \u0026ldquo;Sign up\u0026rdquo; Use your work email (note: public domains like gmail.com are not allowed) Verify your email address Already have an account?\nGo to superblocks.com Click \u0026ldquo;Login\u0026rdquo; Enter your credentials Step 2: Database Configuration If you\u0026rsquo;re attending a guided workshop, you\u0026rsquo;ll be provided with database credentials and can skip the RDS setup section below.\nOption 1: Guided Workshop\n1. Locate Your Provided Credentials\nUse the workshop credentials provided by your instructor Note down the following: Database host Database name Username Password Option 2: Self-Paced Workshop (AWS RDS Setup)\n1. Create an RDS Instance\nGo to the AWS Console and navigate to RDS Click \u0026ldquo;Create database\u0026rdquo; Choose PostgreSQL as the engine Select \u0026ldquo;Free tier\u0026rdquo; template if available Configure basic settings: DB instance identifier: sb-workshop-db Master username: postgres Create a secure master password 2. Configure Network Settings\nVPC: Choose your default VPC Public access: Yes (for workshop purposes only) VPC security group: Create new Allow inbound PostgreSQL (port 5432) from your IP 3. Configure Database Options\nInitial database name: workshop_db Leave other settings as default Click \u0026ldquo;Create database\u0026rdquo; 4. Wait for Database Creation (~5-10 minutes)\nNote down your database endpoint when available Save your credentials securely Configure Superblocks Connection\nIn Superblocks, go to Integrations Click \u0026ldquo;Add Integration\u0026rdquo; Search for and select \u0026ldquo;PostgreSQL\u0026rdquo; Enter your database details: Host: Your RDS endpoint or provided workshop host Port: 5432 (default for Postgres) Database: Your database name Username and password Click \u0026ldquo;Test Connection\u0026rdquo; to verify and click \u0026ldquo;Create\u0026rdquo; Step 3: Generate Mock Data If you\u0026rsquo;re in a guided workshop, the mock data will already be populated in your provided database. You can skip this section.\nDatabase Structure Let\u0026rsquo;s set up your database. The setup script will create these tables and views in the dm_operations schema:\ndm_operations.inventory\n- category_name (varchar) -- Paper category (e.g., \u0026#34;Copy Paper\u0026#34;, \u0026#34;Card Stock\u0026#34;) - location_name (varchar) -- Branch location - current_stock (integer) -- Current quantity in stock - reorder_point (integer) -- Minimum stock level before reorder - unit_price (numeric) -- Price per unit dm_operations.orders\n- order_id (integer) -- Unique order identifier - status (varchar) -- Order status (e.g., \u0026#34;Pending\u0026#34;, \u0026#34;Shipped\u0026#34;) - order_date (timestamp) -- When the order was placed - total_amount (numeric) -- Total order value dm_operations.sales\n- sale_id (integer) -- Unique sale identifier - sale_date (timestamp) -- When the sale occurred - location_name (varchar) -- Branch where sale occurred - total_amount (numeric) -- Total sale value dm_operations.inventory_location_status (View)\n- inventory_id (integer) -- Unique inventory identifier - location_name (text) -- Branch location - current_stock (integer) -- Current quantity in stock - stock_status (text) -- Status based on stock level ... dm_operations.pending_orders (View)\n- inventory_id (integer) -- Inventory reference - location_name (text) -- Branch location - num_orders (integer) -- Number of pending orders - total_quantity_ordered (integer) -- Total items on order ... dm_operations.sales_velocity (View)\n- inventory_id (integer) -- Inventory reference - location_name (text) -- Branch location - num_sales (integer) -- Number of sales - total_revenue (decimal) -- Total revenue - daily_velocity (decimal) -- Average daily sales rate ... Setup Steps 1. Clone the Workshop Repository\ngit clone https://github.com/nvardaro-sb/acme-inc-db-setup.git cd acme-inc-db-setup 2. Set Up Python Environment\nCreate and activate a virtual environment to keep dependencies isolated:\n# Create virtual environment python -m venv venv # Activate virtual environment # On macOS/Linux: source venv/bin/activate # On Windows: # venv\\Scripts\\activate 3. Install Required Dependencies\n# Install dependencies pip install -r requirements.txt 4. Configure Database Connection\nCopy the example .env file: cp example.env .env Edit .env with your database credentials: DB_USER= DB_PASSWORD= DB_HOST= DB_PORT=5432 DB_NAME= 5. Run the Setup Script\n./setup_database.sh This script will create the necessary tables and populate sample data for the application.\nThe setup script will overwrite existing data in the specified tables. Make sure you\u0026rsquo;re using a fresh database or one dedicated to this workshop.\nVerify Setup 1. Test Database Access\nSELECT COUNT(*) FROM dm_operations.inventory; If you can\u0026rsquo;t connect to the database or access any part of Superblocks, please ask for assistance or reach out to Superblocks support before proceeding.\nNext Steps After completing the setup, we\u0026rsquo;ll explore the technical concepts behind our application.\n"
},
{
	"uri": "//localhost:1313/1_moduleone_overview/02_technicalissueproblem.html",
	"title": "Technical Problem",
	"tags": [],
	"description": "",
	"content": "The Technical Challenge The Hidden Cost of DIY Development When enterprises build their own internal tools and platforms, they quickly discover that the true cost goes far beyond initial development. What starts as \u0026ldquo;just a few internal tools\u0026rdquo; soon becomes a massive drain on resources, innovation, and team morale.\nThe Infrastructure Trap Every new tool adds complexity to your system. Security patches, scaling issues, and integration problems multiply. Your team gets caught in an endless cycle of maintenance, while technical debt accumulates with each new feature. Soon, the infrastructure that was meant to help your business becomes a burden that holds it back.\nThe Innovation Tax As maintenance demands grow, your team\u0026rsquo;s ability to innovate plummets. Developers spend their days managing infrastructure instead of building features. Knowledge becomes siloed, compliance overhead increases, and your time-to-market suffers. The worst part? This tax compounds over time - the more you build, the more resources you need just to keep the lights on.\nBreaking Free from DIY Superblocks offers a fundamentally different approach. Instead of building and maintaining everything yourself, you get a complete platform that just works - one that grows with you without growing your maintenance burden.\nNo more wrestling with infrastructure - authentication, permissions, and audit logs are ready from day one. No more reinventing the wheel - our pre-built components and templates eliminate repetitive work. And no more compliance headaches - enterprise-grade security is built into everything we do.\nThe result? Your team can focus entirely on creating value for your business. Features that would take months to build can be shipped in days. Developers can spend their time on innovation instead of maintenance. Most importantly, you get the scalability, security, and speed your business needs without the traditional overhead.\nReady to Transform Your Development? Let\u0026rsquo;s see how Superblocks can accelerate your team\u0026rsquo;s productivity with your first project.\n"
},
{
	"uri": "//localhost:1313/3_modulethree_frontend.html",
	"title": "Building the Frontend",
	"tags": [],
	"description": "",
	"content": "Building the Frontend What You\u0026rsquo;ll Learn In this module, you\u0026rsquo;ll build the frontend of the Acme Incorporated dashboard. You\u0026rsquo;ll:\nCreate a responsive navigation header Build interactive filter components Display key metrics with hero stats Create a dynamic data table Add interactive Plotly charts We\u0026rsquo;ll use Superblocks\u0026rsquo; UI components and templates to build each part of the dashboard.\nTime to Complete This module should take approximately 30 minutes to complete.\nNext Steps Let\u0026rsquo;s start building your dashboard, beginning with the navigation header.\n"
},
{
	"uri": "//localhost:1313/3_modulethree_frontend/03_herostats.html",
	"title": "Building the Hero Stats Section",
	"tags": [],
	"description": "",
	"content": "Building the Hero Stats Section Let\u0026rsquo;s add key metrics to your dashboard using hero stats.\nStep 1: Add the Stats Section Create a new section: Click \u0026ldquo;+ Add Section\u0026rdquo; below the filters A column component will be added automatically Add the template: Click the template icon next to \u0026ldquo;Add Component\u0026rdquo; Search for \u0026ldquo;Hero stats with label below\u0026rdquo; Click \u0026ldquo;Insert\u0026rdquo; Step 2: Configure Your Stats Add a fourth stat: Copy the third stat tile (CMD/CTRL + C) Paste to create a new tile (CMD/CTRL + V) Update the stats: Total Inventory (use \u0026ldquo;$\u0026rdquo;) Low Stock Items (use \u0026ldquo;items\u0026rdquo;) Pending Orders (use \u0026ldquo;orders\u0026rdquo;) YTD Sales (use \u0026ldquo;$\u0026rdquo;) Simplify the display: Remove the percentage changes Remove the parent container Example Here\u0026rsquo;s how your hero stats section should look after completion: Next Steps Next, we\u0026rsquo;ll create the main dashboard section with your data table and charts.\n"
},
{
	"uri": "//localhost:1313/4_modulefour_backend/03_herostatsapis.html",
	"title": "Implementing the Hero Stats APIs",
	"tags": [],
	"description": "",
	"content": "Implementing the Hero Stats APIs Let\u0026rsquo;s create APIs for your hero stats using parallel execution to fetch multiple metrics simultaneously.\nStep 1: Set Up the API Open API Builder: Press CMD/CTRL + U Create parallel API: Click \u0026ldquo;Add new API\u0026rdquo; Hover over \u0026ldquo;Control Blocks\u0026rdquo; Select \u0026ldquo;Run Parallel\u0026rdquo; Click the pen icon next to \u0026lsquo;API1\u0026rsquo; and rename it to \u0026ldquo;get_herostats\u0026rdquo; Step 2: Configure Parallel Paths Add paths: Click the Parallel block Click + to add three new paths Name your paths: Path1: \u0026ldquo;get_inventory\u0026rdquo; Path2: \u0026ldquo;get_lowstock\u0026rdquo; Path3: \u0026ldquo;get_pendingorders\u0026rdquo; Path4: \u0026ldquo;get_ytdsales\u0026rdquo; Step 3: Add Your Queries Add these SQL queries to each path:\nTotal Inventory Value (Path1):\nSELECT SUM(current_stock * unit_price) FROM dm_operations.inventory; Low Stock Items (Path2):\nSELECT COUNT(*) FROM dm_operations.inventory WHERE current_stock \u0026lt;= reorder_point; Pending Orders (Path3):\nSELECT COUNT(*) FROM dm_operations.orders WHERE status = \u0026#39;Pending\u0026#39;; YTD Sales (Path4):\nSELECT SUM(total_amount) FROM dm_operations.sales WHERE EXTRACT(YEAR FROM sale_date) = EXTRACT(YEAR FROM CURRENT_DATE); ## Step 4: Connect Your Stats Update each stat with its API response: 1. Total Inventory: {{get_herostats.response.get_inventory}}\n2. Low Stock Items: {{get_herostats.response.get_lowstock}}\n3. Pending Orders: {{get_herostats.response.get_pendingorders}}\n4. YTD Sales: {{get_herostats.response.get_ytdsales}}\n## Testing 1. Check your stats: - Run the API - Verify all numbers appear - Check formatting If stats are missing, click \u0026ldquo;Run API\u0026rdquo; in the API Builder Tool.\n## Next Steps Let\u0026#39;s create the Plotly visualization APIs for your charts. "
},
{
	"uri": "//localhost:1313/2_moduletwo_preqandsetup/03_technicalconcepts.html",
	"title": "Technical Concepts",
	"tags": [],
	"description": "",
	"content": "Technical Concepts Superblocks Architecture Superblocks uses a modern three-plane architecture:\nControl Plane (Superblocks Cloud)\nHandles user authentication and permissions Manages application definitions and configurations Provides centralized logging and monitoring Compute Plane (Execution Layer)\nExecutes API calls and functions Processes data transformations Handles request routing and retries Data Plane (Your Data Sources)\nYour databases (SQL, NoSQL) Internal services and APIs Data warehouses and storage Deployment Options You can deploy Superblocks in two ways, choosing where to run the compute plane based on your security needs:\nCloud (Default)\nCompute plane runs in Superblocks\u0026rsquo; secure infrastructure Zero setup with instant deployment Data flows through but is never stored On-premise Agent\nCompute plane runs inside your VPC via lightweight agent All data processing stays in your network Open-source agent for full auditability On-Premise Agent Architecture The following diagram shows how the On-Premise Agent integrates with your infrastructure:\nRequest Flow The following diagram shows the request flow when using the On-Premise Agent:\nExecuting Requests via the On-Premise Agent The browser makes a separate secure request to the on-premise agent inside of your network to execute an API or database call The agent securely retrieves the API definition from the closest cache on the Global Superblocks Edge Network The agent executes the API inside your private network querying your databases or internal APIs and sends the data directly to the browser Next Steps Now that you understand the Superblocks architecture, let\u0026rsquo;s proceed with building our application. As an optional step, you can set up the On-Premise Agent (OPA) locally for secure database access. This local setup can be valuable for development and testing purposes.\n"
},
{
	"uri": "//localhost:1313/6_modulesix_governance/03_testing.html",
	"title": "Testing Access Controls",
	"tags": [],
	"description": "",
	"content": "Testing Access Controls Let\u0026rsquo;s verify your access controls work correctly by testing with different user scenarios.\nStep 1: Test in Preview Open Preview mode:\nClick \u0026ldquo;Preview\u0026rdquo; in the top-right This shows a preview of the dashboard and allows you to see how it would look for different users Try different use cases:\nAdd your name to the rule to grant access to the Invoices tab Check what you can see in the preview Verify restrictions work Test Access Rules Test restricted access:\nLog in as yourself (if your name is not John Smith, Sarah Johnson, or Michael Lee) Verify Invoices tab is hidden Test with access:\nAdd your name to the rule: {{[\u0026#39;John Smith\u0026#39;, \u0026#39;Sarah Johnson\u0026#39;, \u0026#39;Michael Lee\u0026#39;, \u0026#39;Your Name\u0026#39;].includes(Global.user.name)}} Verify Invoices tab appears Security Checklist ‚úì User names display correctly ‚úì Access rules work consistently ‚úì UI updates properly ‚úì Sensitive data is protected\nTest thoroughly! Try different users and edge cases to ensure your security is solid.\nWorkshop Complete! Congratulations! You\u0026rsquo;ve built:\nA modern dashboard frontend Powerful backend APIs AI features with AWS Bedrock Enterprise security controls A fully tested application Your Acme Incorporated dashboard is ready for production!\n"
},
{
	"uri": "//localhost:1313/5_modulefive_bedrock/03_uiforanalysis.html",
	"title": "UI Component for Analysis",
	"tags": [],
	"description": "",
	"content": "Create a UI Component for the Analysis üñ•Ô∏è Now that we have our Bedrock connection set up, let\u0026rsquo;s create a powerful inventory analysis feature that can provide insights about current inventory levels, identify potential stockouts, and recommend transfering strategies.\nStep 1: Create a UI Component for the Analysis üñ•Ô∏è Now, let\u0026rsquo;s create a UI component to display the inventory analysis:\nNavigate to UI Builder in the left sidebar Open your dashboard page Add a new container to your dashboard Add a heading component with the text \u0026ldquo;Inventory Analysis\u0026rdquo; Add a button component labeled \u0026ldquo;Analyze Inventory\u0026rdquo; Configure the button\u0026rsquo;s onClick event: Select \u0026ldquo;Run API\u0026rdquo; Choose your \u0026ldquo;InventoryAnalysis\u0026rdquo; API For the success action, select \u0026ldquo;Update State\u0026rdquo; Set the state key to \u0026ldquo;inventoryAnalysis\u0026rdquo; Add a text component below the button Configure the text component to display the analysis: Set the content to {{state.inventoryAnalysis.steps.AnalyzeInventory.body}} Enable markdown rendering Add a loading state to improve user experience ::alert[Superblocks\u0026rsquo; state management system makes it easy to store and display API results. The state is reactive, so your UI will automatically update when the data changes.]\nStep 3: Test Your Inventory Analysis Feature ‚úÖ Preview your application Click the \u0026ldquo;Analyze Inventory\u0026rdquo; button Wait for the analysis to complete Review the insights provided by AWS Bedrock Examine the visualization to identify at-risk products ::alert[You\u0026rsquo;ve now created a powerful inventory analysis feature that leverages AWS Bedrock to provide actionable insights. This feature demonstrates how Superblocks and AWS Bedrock can work together to transform raw data into valuable business intelligence.]{header=\u0026ldquo;Success\u0026rdquo; type=\u0026ldquo;success\u0026rdquo;}\n"
},
{
	"uri": "//localhost:1313/4_modulefour_backend.html",
	"title": "Building the Backend",
	"tags": [],
	"description": "",
	"content": "Building the Backend What You\u0026rsquo;ll Learn In this module, you\u0026rsquo;ll create the backend services that power your Acme Incorporated dashboard. You\u0026rsquo;ll:\nCreate dynamic dropdown APIs for filtering Build a filtered inventory data API Implement parallel APIs for real-time metrics Create interactive Plotly visualizations Connect your frontend to live data We\u0026rsquo;ll write SQL queries, process data with Python, and connect everything to your frontend components.\nTime to Complete This module should take approximately 45 minutes to complete.\nNext Steps Let\u0026rsquo;s start by creating APIs for your dropdown components. These will enable dynamic filtering and interactive visualizations in your dashboard.\n"
},
{
	"uri": "//localhost:1313/4_modulefour_backend/04_plotlyapis.html",
	"title": "Creating Plotly Visualization APIs",
	"tags": [],
	"description": "",
	"content": "Creating Plotly Visualization APIs Let\u0026rsquo;s create two interactive Plotly charts: a location-based sales chart and a monthly trends visualization.\nStep 1: Create Location Sales Chart Open API Builder:\nPress CMD/CTRL + U Create the API:\nClick \u0026ldquo;Add new API\u0026rdquo; Select your database integration Click the pen icon next to \u0026lsquo;API1\u0026rsquo; and rename it to \u0026ldquo;location_chart\u0026rdquo; Add your query:\nSELECT location_name, SUM(total_amount) as total_sales FROM dm_operations.sales GROUP BY location_name ORDER BY total_sales DESC; Add a Python Function Step and add the below code:\nimport plotly.express as px import pandas as pd # Create bar chart fig = px.bar( Step1.output, x=\u0026#34;location_name\u0026#34;, y=\u0026#34;total_sales\u0026#34;, title=\u0026#34;Sales by Location\u0026#34;, labels={ \u0026#34;total_sales\u0026#34;: \u0026#34;Total Sales ($)\u0026#34;, \u0026#34;location_name\u0026#34;: \u0026#34;Branch Location\u0026#34; }, color=\u0026#34;location_name\u0026#34; ) # Style the chart fig.update_layout( template=\u0026#34;plotly_white\u0026#34;, showlegend=False, height=400 ) return fig.to_json() Step 2: Create Monthly Trends Chart Create the API:\nClick \u0026ldquo;Add new API\u0026rdquo; Select your database integration Click the pen icon next to \u0026lsquo;API1\u0026rsquo; and rename it to \u0026ldquo;monthly_trends\u0026rdquo; Add your query:\nSELECT DATE_TRUNC(\u0026#39;month\u0026#39;, sale_date) as month, SUM(total_amount) as total_sales, COUNT(*) as number_of_orders FROM dm_operations.sales WHERE sale_date \u0026gt;= CURRENT_DATE - INTERVAL \u0026#39;12 months\u0026#39; GROUP BY DATE_TRUNC(\u0026#39;month\u0026#39;, sale_date) ORDER BY month; Add a Python Function Step and add the below code:\nimport plotly.graph_objects as go import pandas as pd # Prepare data monthly_data = pd.DataFrame(Step1.output) monthly_data[\u0026#34;total_sales\u0026#34;] = pd.to_numeric(monthly_data[\u0026#34;total_sales\u0026#34;]) monthly_data[\u0026#34;number_of_orders\u0026#34;] = pd.to_numeric(monthly_data[\u0026#34;number_of_orders\u0026#34;]) # Create figure fig = go.Figure() # Add sales trend fig.add_trace( go.Scatter( x=monthly_data[\u0026#34;month\u0026#34;], y=monthly_data[\u0026#34;total_sales\u0026#34;], name=\u0026#34;Total Sales\u0026#34;, line=dict(color=\u0026#34;blue\u0026#34;, width=2) ) ) # Add orders trend fig.add_trace( go.Scatter( x=monthly_data[\u0026#34;month\u0026#34;], y=monthly_data[\u0026#34;number_of_orders\u0026#34;], name=\u0026#34;Number of Orders\u0026#34;, yaxis=\u0026#34;y2\u0026#34;, line=dict(color=\u0026#34;red\u0026#34;, width=2) ) ) # Style the chart fig.update_layout( title=\u0026#34;Monthly Sales Trends (Last 12 Months)\u0026#34;, xaxis=dict(title=\u0026#34;Month\u0026#34;), yaxis=dict( title=\u0026#34;Total Sales ($)\u0026#34;, titlefont=dict(color=\u0026#34;blue\u0026#34;), tickfont=dict(color=\u0026#34;blue\u0026#34;) ), yaxis2=dict( title=\u0026#34;Number of Orders\u0026#34;, titlefont=dict(color=\u0026#34;red\u0026#34;), tickfont=dict(color=\u0026#34;red\u0026#34;), anchor=\u0026#34;x\u0026#34;, overlaying=\u0026#34;y\u0026#34;, side=\u0026#34;right\u0026#34; ), template=\u0026#34;plotly_white\u0026#34;, height=400 ) return fig.to_json() ## Step 3: Connect Your Charts 1. Set up location chart: - Select first chart component - Clear \u0026#34;Header\u0026#34; - Set \u0026#34;Definition\u0026#34; to \u0026#34;Plotly\u0026#34; - Set \u0026#34;Plotly chart JSON\u0026#34; to: {{location_chart.response}} 2. Set up trends chart: - Select second chart component - Clear \u0026#34;Header\u0026#34; - Set \u0026#34;Definition\u0026#34; to \u0026#34;Plotly\u0026#34; - Set \u0026#34;Plotly chart JSON\u0026#34; to: {{monthly_trends.response}} Your charts are interactive! Users can hover over points, zoom, and pan. If charts don\u0026rsquo;t appear, try clicking \u0026ldquo;Run API\u0026rdquo; in the API Builder Tool.\n## Testing 1. Test rendering: - Check both charts appear - Verify data accuracy - Test hover tooltips 2. Test interactions: - Try zooming in/out - Pan across the data - Click legend items ## Next Steps Now that your dashboard is working, let\u0026#39;s integrate with AWS Bedrock. "
},
{
	"uri": "//localhost:1313/3_modulethree_frontend/04_bodysection.html",
	"title": "Creating the Body Section",
	"tags": [],
	"description": "",
	"content": "Creating the Body Section Let\u0026rsquo;s create the main dashboard layout with a data table and charts.\nStep 1: Set Up the Layout Create the section: Add a new section (adds a column automatically) Set section height to \u0026ldquo;Fill Viewport\u0026rdquo; Configure the column: Set layout to \u0026ldquo;Horizontal\u0026rdquo; Step 2: Add Containers Left container (for table): Add a container component Width will be \u0026ldquo;Fluid\u0026rdquo; (¬æ of section) Set layout to \u0026ldquo;Vertical\u0026rdquo; Set height to \u0026ldquo;Fill Parent\u0026rdquo; Right container (for charts): Add a container component Set width to \u0026ldquo;Fill Parent\u0026rdquo; Set layout to \u0026ldquo;Vertical\u0026rdquo; Set height to \u0026ldquo;Fill Parent\u0026rdquo; Step 3: Add the Table In the left container: Add a Table component Set height to \u0026ldquo;Fill Parent\u0026rdquo; Simplify the table: Remove the default header Remove the search bar Remove the download button Step 4: Add Charts In the right container: Add two chart components Set both heights to \u0026ldquo;Fill Parent\u0026rdquo; The \u0026ldquo;Fill Parent\u0026rdquo; and \u0026ldquo;Fill Viewport\u0026rdquo; settings ensure your components use the available space effectively and create a responsive layout.\nExample Here\u0026rsquo;s how your body section should look after completion: Next Steps Great work! Next, we\u0026rsquo;ll implement the APIs to populate your application with data.\n"
},
{
	"uri": "//localhost:1313/2_moduletwo_preqandsetup/04_opalocal.html",
	"title": "On-Premise Agent (Optional)",
	"tags": [],
	"description": "",
	"content": "Local On-Premise Agent (OPA) Setup Overview The On-Premise Agent (OPA) allows you to securely execute queries and access local services during development. When running locally, the OPA:\nRuns as a Docker container on your machine Provides secure access to local databases and services Maintains data privacy by processing requests within your environment The On-Premise Agent is optional for this workshop and can be skipped.\nPrerequisites Before starting, ensure you have:\nDocker Desktop installed and running Terminal/Command Prompt access A Superblocks account with admin access Setup Process Step 1: Generate an Agent Token First, create a secure token for your local agent:\nIn Superblocks, navigate to Organization Settings ‚Üí Access Tokens Click Create token Configure the token: Name: \u0026ldquo;Local Development Agent\u0026rdquo; Type: Agent key Expiration: 90 days (default) Important: Save the generated token securely - it cannot be viewed again Step 2: Launch the Agent Run this command in your terminal, replacing {AGENT_KEY} with your token:\n# Download and start the OPA container curl -s https://raw.githubusercontent.com/superblocksteam/agent/main/compose.yaml | \\ SUPERBLOCKS_AGENT_KEY=\u0026#34;{AGENT_KEY}\u0026#34; \\ SUPERBLOCKS_AGENT_HOST_URL=\u0026#34;http://localhost:8080\u0026#34; \\ SUPERBLOCKS_AGENT_TAGS=\u0026#34;profile:*\u0026#34; \\ SUPERBLOCKS_DOCKER_AGENT_TAG=\u0026#34;latest\u0026#34; \\ SUPERBLOCKS_AGENT_DATA_DOMAIN=\u0026#34;app.superblocks.com\u0026#34; \\ docker compose -p superblocks -f - up Step 3: Connect Local Services To connect your local databases or services:\nOpen the Integrations page in Superblocks Select your integration type Click Manage (‚ãÆ menu) Configure the connection: Host: Use host.docker.internal instead of localhost Port: Use the service\u0026rsquo;s exposed port Credentials: Enter your local service credentials Verification Step 4: Check Agent Status Go to Organization Settings ‚Üí On-Premise Agents Switch to On-Premise Deployment view Look for your agent with Active status Step 5: Test the Connection Create a new API in Superblocks Select your local integration Run a test query Verify the results in the response panel Troubleshooting If you encounter issues:\nCheck the Superblocks documentation Review agent logs for specific errors Check out the Troubleshooting OPA guide for common issues and solutions. The On-Premise Agent is optional for this workshop. If you\u0026rsquo;re using the cloud offering with a cloud database, you can skip this section.\n"
},
{
	"uri": "//localhost:1313/5_modulefive_bedrock.html",
	"title": "Integrating with AWS Bedrock",
	"tags": [],
	"description": "",
	"content": "Enhancing Your Application with AWS Bedrock ü§ñ üöÄ What You\u0026rsquo;ll Learn In this module, you\u0026rsquo;ll integrate AWS Bedrock\u0026rsquo;s powerful generative AI capabilities into your Superblocks application to provide intelligent business insights. You\u0026rsquo;ll learn how to:\nConfigure AWS Bedrock integration within Superblocks with minimal code Build AI-powered inventory analysis features using foundation models AWS Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies through a unified API. With Superblocks, you can easily integrate these powerful AI capabilities into your applications without needing deep machine learning expertise.\n::alert[The examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.]{header=\u0026ldquo;Warning\u0026rdquo; type=\u0026ldquo;warning\u0026rdquo;}\nBusiness Value By integrating AWS Bedrock with your Superblocks application, you\u0026rsquo;ll enable:\nData-Driven Decision Making üìä: Surface actionable insights from your inventory and sales data Operational Efficiency ‚öôÔ∏è: Automate analysis that would typically require data science expertise Enhanced User Experience üåü: Provide natural language interfaces for complex data queries Predictive Capabilities üîÆ: Anticipate inventory needs before they become critical Rapid AI Implementation ‚ö°: Deploy AI features in days instead of months Time to Complete This module should take approximately 45 minutes to complete.\nNext Steps Let\u0026rsquo;s begin by setting up your AWS Bedrock connection in Superblocks.\n"
},
{
	"uri": "//localhost:1313/6_modulesix_governance.html",
	"title": "Governance &amp; Access Controls",
	"tags": [],
	"description": "",
	"content": "Governance \u0026amp; Access Controls What You\u0026rsquo;ll Learn In this final module, you\u0026rsquo;ll secure your Acme Incorporated dashboard with enterprise-grade access controls. You\u0026rsquo;ll:\nSet up user identification Display user information Use the Global.user context Implement access controls Create visibility rules Secure sensitive features Test security measures Verify user permissions Validate access rules This module will secure your application with enterprise-grade access controls, ensuring only authorized users can access sensitive features.\nTime to Complete This module should take approximately 20 minutes to complete.\nNext Steps Let\u0026rsquo;s start by implementing user identification in your dashboard.\n"
},
{
	"uri": "//localhost:1313/5_modulefive_bedrock/07_bedrocksummary.html",
	"title": "Bedrock Module Summary",
	"tags": [],
	"description": "",
	"content": "AWS Bedrock Integration Summary Congratulations! You\u0026rsquo;ve successfully integrated AWS Bedrock with your Superblocks application to create powerful AI-enhanced features:\nInventory Analysis üì¶: Automated insights about inventory status and reordering needs Natural Language Queries üí¨: A user-friendly interface for exploring sales data Predictive Analytics üîÆ: Forward-looking inventory forecasts to prevent stockouts Conversational Assistant ü§ñ: A business assistant that helps users interact with data Key Takeaways Simplified AI Integration: Superblocks makes it easy to connect to AWS Bedrock without deep ML expertise Business Value: These AI features provide actionable insights that drive better business decisions Development Efficiency: What would typically take weeks or months to build was accomplished in hours Customizability: The patterns you\u0026rsquo;ve learned can be applied to many different business scenarios ::alert[The combination of AWS Bedrock and Superblocks enables you to build sophisticated AI features with minimal code, making advanced AI capabilities accessible to developers of all skill levels.]{header=\u0026ldquo;Important\u0026rdquo; type=\u0026ldquo;info\u0026rdquo;}\nNext Steps Now that you\u0026rsquo;ve integrated AWS Bedrock, consider these next steps:\nCustomize the prompts to better fit your specific business needs Experiment with different foundation models to find the best fit for each use case Add more sophisticated data preprocessing to improve the quality of AI outputs Implement feedback loops to continuously improve your AI features ::alert[Remember that foundation models improve over time, and prompt engineering is an iterative process. Regularly review and refine your prompts to get the best results.]{header=\u0026ldquo;Tip\u0026rdquo; type=\u0026ldquo;info\u0026rdquo;}\nIn the next module, we\u0026rsquo;ll explore how to implement proper governance and access controls for your application.\n"
},
{
	"uri": "//localhost:1313/7_moduleseven_deployment.html",
	"title": "Deployment",
	"tags": [],
	"description": "",
	"content": "Deploying Your Application What You\u0026rsquo;ll Learn In this module, you\u0026rsquo;ll deploy your Acme Incorporated dashboard to production. You\u0026rsquo;ll learn how to:\nDeploy using different methods Use the Superblocks UI Set up continuous deployment Use the Superblocks CLI Follow deployment best practices Review changes before deployment Automate your workflow Monitor your application Time to Complete This module should take approximately 15 minutes to complete.\nNext Steps Let\u0026rsquo;s learn how to deploy your application to production.\n"
},
{
	"uri": "//localhost:1313/8_moduleeight_nextsteps.html",
	"title": "Next Steps",
	"tags": [],
	"description": "",
	"content": "Next Steps Congratulations on building and deploying your Acme Incorporated dashboard! Let\u0026rsquo;s explore how to enhance it further.\nAdvanced Features Take your dashboard to the next level with these powerful additions:\n1. Enhanced Visualizations Add trend forecasting charts Create interactive heat maps Build custom KPI widgets 2. Custom Integrations Connect more data sources Add real-time data streams Integrate business tools Enable webhook triggers 3. AI/ML Capabilities Implement predictive analytics Add natural language queries Enable automated insights Create smart alerts Resources Documentation Superblocks Docs API Reference Component Library Learning Video Tutorials Sample Apps Blog Posts Join our community forum to share ideas and get help from other developers.\nWhat\u0026rsquo;s Next? You\u0026rsquo;ve completed the workshop! You now have:\nA production-ready dashboard Modern architecture Scalable foundation Security best practices Keep building amazing things with Superblocks!\n"
},
{
	"uri": "//localhost:1313/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]